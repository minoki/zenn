---
title: "bfloat16 (brain float16) ã®CPUã«ã‚ˆã‚‹å¯¾å¿œã¨Cè¨€èªã‹ã‚‰ã®åˆ©ç”¨"
emoji: "ğŸ§ "
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["float", "æµ®å‹•å°æ•°ç‚¹æ•°"]
published: true
---

## bfloat16ã¨ã¯

bfloat16 (brain float16, BF16) ã¯æ·±å±¤å­¦ç¿’ã§ä½¿ã‚ã‚Œã‚‹æµ®å‹•å°æ•°ç‚¹å½¢å¼ã§ã€å…ƒã€…GoogleãŒè€ƒæ¡ˆã—ãŸã‚‰ã—ã„ã§ã™ã€‚

* [Tearing Apart Googleâ€™s TPU 3.0 AI Coprocessor](https://www.nextplatform.com/2018/05/10/tearing-apart-googles-tpu-3-0-ai-coprocessor/) (2018-05-10)
* [BFloat16: The secret to high performance on Cloud TPUs | Google Cloud Blog](https://cloud.google.com/blog/products/ai-machine-learning/bfloat16-the-secret-to-high-performance-on-cloud-tpus?hl=en) (2019-08-24)

IEEE 754ã§æ¨™æº–åŒ–ã•ã‚ŒãŸ16ãƒ“ãƒƒãƒˆæµ®å‹•å°æ•°ç‚¹å½¢å¼ã¨ã—ã¦binary16ãŒã‚ã‚Šã¾ã™ãŒã€bfloat16ã¯binary16ã¨æ¯”ã¹ã¦æŒ‡æ•°éƒ¨ã‚’åºƒãï¼ˆbinary32ã¨åŒã˜ï¼‰å–ã£ã¦ã„ã‚‹ã®ãŒç‰¹å¾´ã§ã™ã€‚æ·±å±¤å­¦ç¿’ã§ã¯ç²¾åº¦ã‚ˆã‚Šã‚‚ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãƒ¬ãƒ³ã‚¸ã®æ–¹ãŒé‡è¦ã ã¨ã‹äº‘ã€…ã€‚

```
binary32:
s eeeeeeee mmmm mmmm mmmm mmmm mmmm mmm
^    ^       ^
ç¬¦å·  æŒ‡æ•°éƒ¨  ä»®æ•°éƒ¨ä¸‹ä½ 

binary16:
s eeeee mmmm mmmm mm
^    ^       ^
ç¬¦å·  æŒ‡æ•°éƒ¨  ä»®æ•°éƒ¨ä¸‹ä½ 

bfloat16:
s eeeeeeee mmmm mmm
^    ^       ^
ç¬¦å·  æŒ‡æ•°éƒ¨  ä»®æ•°éƒ¨ä¸‹ä½ 
```

| å½¢å¼ | ç¬¦å· | æŒ‡æ•°éƒ¨ | ä»®æ•°éƒ¨ä¸‹ä½ |
|:-:|:-:|:-:|:-:|
| binary32 | 1ãƒ“ãƒƒãƒˆ | 8ãƒ“ãƒƒãƒˆ | 23ãƒ“ãƒƒãƒˆ |
| binary16 | 1ãƒ“ãƒƒãƒˆ | 5ãƒ“ãƒƒãƒˆ | 10ãƒ“ãƒƒãƒˆ |
| bfloat16 | 1ãƒ“ãƒƒãƒˆ | 8ãƒ“ãƒƒãƒˆ | 7ãƒ“ãƒƒãƒˆ |

## binary32ã¨ã®å¤‰æ›

æŒ‡æ•°éƒ¨ã®å¹…ãŒåŒã˜ãªã®ã§ã€binary32ã‹ã‚‰bfloat16ã«å¤‰æ›ã™ã‚‹ã®ã¯ä¸Šä½16ãƒ“ãƒƒãƒˆã‚’å–ã‚Šå‡ºã™ã ã‘ã§å¯èƒ½ã¨ãªã‚Šã¾ã™ã€‚ãŸã ã€ã“ã®æ–¹æ³•ã ã¨ç«¯æ•°ãŒå˜ãªã‚‹åˆ‡ã‚Šæ¨ã¦ã«ãªã£ã¦ã—ã¾ã„ã¾ã™ã€‚

ä¸Šä½16ãƒ“ãƒƒãƒˆã‚’å–ã‚Šå‡ºã™å‰ã«binary32ã®ãƒ“ãƒƒãƒˆåˆ—è¡¨ç¾ã« `0x8000` ã‚’åŠ ãˆã¦ãŠã‘ã°ã€å››æ¨äº”å…¥ã®äºŒé€²æ³•ç‰ˆã€é›¶æ¨ä¸€å…¥ï¼ˆIEEE 754ç”¨èªã§è¨€ãˆã°roundTiesToAwayï¼‰ãŒã§ããã†ã§ã™ï¼ˆã§ãã‚‹ã‚ˆã­ï¼Ÿï¼‰ã€‚å…ƒã®æµ®å‹•å°æ•°ç‚¹æ•°ãŒNaNã®å ´åˆã¯ã“ã‚Œã ã¨ã¾ãšã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ãŒã€å…¥åŠ›ãŒx86ã‚„Armãªã©ã®æ¨™æº–çš„ãªNaNã§ã‚ã‚‹ã¨ä»®å®šã§ãã‚‹ãªã‚‰ãƒã‚§ãƒƒã‚¯ã‚’çœã„ã¦ã‚‚å•é¡Œãªã„ã§ã—ã‚‡ã†ã€‚

ã‚‚ã†ã¡ã‚‡ã£ã¨ãƒ“ãƒƒãƒˆæ¼”ç®—ã‚’ã‚¬ãƒãƒ£ã‚¬ãƒãƒ£ã‚„ã‚Œã°å¶æ•°ä¸¸ã‚ï¼ˆroundTiesToEvenï¼‰ã‚‚ã§ãã‚‹ã§ã—ã‚‡ã†ã€‚

bfloat16ã‹ã‚‰binary32ã¸ã®å¤‰æ›ã¯ã€å˜ã«ä¸Šä½16ãƒ“ãƒƒãƒˆã«è¨­å®šã™ã‚Œã°å¤§ä¸ˆå¤«ã§ã™ã€‚ã“ã®ã‚„ã‚Šæ–¹ã ã¨å…¥åŠ›ãŒsNaNã®æ™‚ã«å‡ºåŠ›ã‚‚sNaNã¨ãªã£ã¦ã—ã¾ã„ã¾ã™ãŒï¼ˆIEEE 754çš„ã«ã¯å…¥åŠ›ãŒsNaNã ã¨ä¾‹å¤–ãŒç™ºç”Ÿã—ã¦å‡ºåŠ›ã¯qNaNã¨ãªã‚‹ã¹ãï¼‰ã€æ·±å±¤å­¦ç¿’å‘ã‘ã®å¿œç”¨ã§sNaNãŒå•é¡Œã«ãªã‚‹ã“ã¨ã¯ãªã„ã§ã—ã‚‡ã†ã€‚

Cè¨€èªã§å¤‰æ›é–¢æ•°ã‚’æ›¸ããªã‚‰ã€æ¬¡ã®ã‚ˆã†ã«ãªã‚‹ã§ã—ã‚‡ã†ï¼š

```c
typedef uint16_t bf16;

bf16 binary32_to_bfloat16_trunc(float x)
{
    uint32_t u;
    memcpy(&u, &x, 4);
    return u >> 16;
}

bf16 binary32_to_bfloat16_round(float x)
{
    uint32_t u;
    memcpy(&u, &x, 4);
    return (u + 0x8000) >> 16;
}

float bfloat16_to_binary32(bf16 x)
{
    uint32_t u = (uint32_t)x << 16;
    float x;
    memcpy(&x, &u, 4);
    return x;
}
```

ã¨ã„ã†ã‚ã‘ã§ã€bfloat16ã¨binary32ã®å¤‰æ›ã¯ã€ä¸¸ã‚æ–¹æ³•ã«ã“ã ã‚ã‚‰ãªã‘ã‚Œã°CPUå´ã«ç‰¹åˆ¥ãªå‘½ä»¤ãŒãªãã¦ã‚‚ã§ããã†ã§ã™ã­ã€‚

## C/C++ã§ã®æ‰±ã„

C++23ã§ã¯ `<stdfloat>` ã§ `std::bfloat16_t` ãŒä½¿ãˆã‚‹ã‚ˆã†ã«ãªã‚‹ã‚ˆã†ã§ã™ã€‚

* [Fixed width floating-point types (since C++23) - cppreference.com](https://en.cppreference.com/w/cpp/types/floating-point.html)

x86ã®AVX-512 BF16æ‹¡å¼µã§ã¯ã‚¹ã‚«ãƒ©ãƒ¼ã® `__bfloat16` å‹ã¨ãƒ™ã‚¯ãƒˆãƒ«ã® `__m128bh`, `__m256bh`, `__m512bh` å‹ãŒå°å…¥ã•ã‚Œã‚‹ã‚ˆã†ã§ã™ã€‚

Armã®Cæ‹¡å¼µ (ACLE) ã§ã¯ã€ `<arm_neon.h>` ã§ã‚¹ã‚«ãƒ©ãƒ¼ã® `bfloat16_t` å‹ï¼ˆ`__bf16` å‹ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹ï¼‰ã¨ã€ãƒ™ã‚¯ãƒˆãƒ«ã® `bfloat16x4_t`, `bfloat16x8_t` å‹ãŒå°å…¥ã•ã‚Œã‚‹ã‚ˆã†ã§ã™ã€‚

Cè¨€èªã§ã‚‚æ¨™æº–åŒ–ã•ã‚Œã¦ã»ã—ã„â€¦â€¦ã€‚

## ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢å®Ÿè£…ã¨ã„ã†ã‹CPUå®Ÿè£…ã«ã¤ã„ã¦

æœ€è¿‘ã®CPUã‚„GPUã«ã¯bfloat16å‘ã‘ã®å¤‰æ›å‘½ä»¤ã‚„æ¼”ç®—å‘½ä»¤ãŒæ­è¼‰ã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ã“ã®è¨˜äº‹ã§ã¯ã€CPUã§ã®å–ã‚Šæ‰±ã„ã‚’è¦‹ã¦ã¿ã¾ã™ã€‚

### x86ç·¨

[Intel Intrinsics Guide](https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html)ã«ã‚ˆã‚‹ã¨ã€bfloat16ã®ã‚¹ã‚«ãƒ©ãƒ¼ã¯ `__bfloat16` å‹ã§ã€ãƒ™ã‚¯ãƒˆãƒ«ã¯ `__m128bh`, `__m256bh`, `__m512bh` å‹ã§è¡¨ç¾ã•ã‚Œã‚‹ã‚ˆã†ã§ã™ã€‚

#### AVX-512 BF16

* VCVTNE2PS2BF16 (EVEX): binary32â†’bfloat16ã®å¤‰æ›ã€‚2æœ¬ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’1æœ¬ã®ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ã™ã‚‹ã€‚
    * roundTiesToEvenã«ã‚ˆã‚Šä¸¸ã‚ã‚‹ã€‚
    * å‡ºåŠ›ãŒéæ­£è¦åŒ–æ•°ã«ãªã‚‹å ´åˆã¯ä»£ã‚ã‚Šã«0ãŒå‡ºåŠ›ã•ã‚Œã€å…¥åŠ›ã®éæ­£è¦åŒ–æ•°ã¯0ã¨ã—ã¦æ‰±ã‚ã‚Œã‚‹ã€‚
    * MXCSRã¯å‚ç…§ã‚‚æ›´æ–°ã‚‚ã•ã‚Œãªã„ã€‚ä¾‹å¤–ã¯æŠ‘åˆ¶ã•ã‚Œã‚‹ã€‚
* VCVTNEPS2BF16 (EVEX): binary32â†’bfloat16ã®å¤‰æ›ã€‚1æœ¬ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’1æœ¬ã®ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ã™ã‚‹ã€‚
    * è©³ç´°ã¯VCVTNE2PS2BF16ã¨åŒæ§˜ã€‚
* VDPBF16PS: bfloat16ãƒ™ã‚¯ãƒˆãƒ«2æœ¬ã®ãƒ‰ãƒƒãƒˆç©ã‚’è¨ˆç®—ã—ã€binary32ã®ã‚¢ã‚­ãƒ¥ãƒ ãƒ¬ãƒ¼ã‚¿ãƒ¼ã«åŠ ãˆã‚‹ã€‚
    * æ¼”ç®—ã®éš›ã®è©³ç´°ã¯VCVTNE2PS2BF16ã¨åŒæ§˜ã€‚

AVX-512 BF16ã¯AVX10.1ã®ä¸€éƒ¨ã¨ãªã‚Šã¾ã™ã€‚

ã“ã‚Œã‚‰ã«å¯¾å¿œã™ã‚‹Cã®çµ„ã¿è¾¼ã¿é–¢æ•°ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚

```c
#include <immintrin.h>

// VCVTNE2PS2BF16ã«å¯¾å¿œã™ã‚‹å‘½ä»¤ã®ã†ã¡ã€ä»£è¡¨çš„ãªã‚‚ã®ï¼ˆå®Ÿéš›ã«ã¯maskä»˜ãã®å¤‰ç¨®ã‚‚ã‚ã‚‹ï¼‰
__m128bh _mm_cvtne2ps_pbh(__m128, __m128);
__m256bh _mm256_cvtne2ps_pbh(__m256, __m256);
__m512bh _mm512_cvtne2ps_pbh(__m512, __m512);

// VCVTNEPS2BF16ã«å¯¾å¿œã™ã‚‹å‘½ä»¤ã®ã†ã¡ã€ä»£è¡¨çš„ãªã‚‚ã®ï¼ˆå®Ÿéš›ã«ã¯maskä»˜ãã®å¤‰ç¨®ã‚‚ã‚ã‚‹ï¼‰
__m128bh _mm_cvtneps_pbh(__m128);
__m256bh _mm256_cvtneps_pbh(__m256);
__m512bh _mm512_cvtneps_pbh(__m512);

// VDPBF16PSã«å¯¾å¿œã™ã‚‹å‘½ä»¤ã®ã†ã¡ã€ä»£è¡¨çš„ãªã‚‚ã®ï¼ˆå®Ÿéš›ã«ã¯maskä»˜ãã®å¤‰ç¨®ã‚‚ã‚ã‚‹ï¼‰
__m128 _mm_dpbf16_ps(__m128, __m128bh, __m128bh);
__m256 _mm256_dpbf16_ps(__m256, __m256bh, __m256bh);
__m512 _mm512_dpbf16_ps(__m512, __m512bh, __m512bh);

// ãã®ä»–ï¼ˆå®Ÿéš›ã«ã¯maskä»˜ãã®å¤‰ç¨®ã‚‚ã‚ã‚‹ï¼‰
__bfloat16 _mm_cvtness_sbh(float a);
__m128 _mm_cvtpbh_ps(__m128bh a);
__m256 _mm256_cvtpbh_ps(__m128bh a);
__m512 _mm512_cvtpbh_ps(__m256bh a);
float _mm_cvtsbh_ss(__bfloat16 a);
```

#### AVX-NE-CONVERT

AVX-NE-CONVERTã¯bfloat16ã‚„binary16ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’binary32ã«å¤‰æ›ã™ã‚‹å‘½ä»¤ã‚’æä¾›ã—ã¾ã™ã€‚ä¸€éƒ¨ã€AVX-512 BF16ã®å‘½ä»¤ã‚’AVXå‘ã‘ã«æŒã£ã¦ããŸã‚‚ã®ã‚‚ã‚ã‚Šã¾ã™ã€‚

* VBCSTNEBF162PS: ãƒ¡ãƒ¢ãƒªä¸Šã®bfloat16ã‚¹ã‚«ãƒ©ãƒ¼ã‚’binary32ã«å¤‰æ›ã—ã¦ãƒ™ã‚¯ãƒˆãƒ«ã«ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆã™ã‚‹ã€‚
* VCVTNEEBF162PS: ãƒ¡ãƒ¢ãƒªä¸Šã®bfloat16ãƒ™ã‚¯ãƒˆãƒ«ã®å¶æ•°ç•ªç›® (even) ã®è¦ç´ ã‚’binary32ã«å¤‰æ›ã™ã‚‹ã€‚
* VCVTNEOBF162PS: ãƒ¡ãƒ¢ãƒªä¸Šã®bfloat16ãƒ™ã‚¯ãƒˆãƒ«ã®å¥‡æ•°ç•ªç›® (odd) ã®è¦ç´ ã‚’binary32ã«å¤‰æ›ã™ã‚‹ã€‚
* VCVTNEPS2BF16 (VEX): AVX-512 BF16ã®åŒåã®å‘½ä»¤ã¨åŒã˜ã“ã¨ã‚’ã™ã‚‹ã€‚VEXã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚Œã‚‹ã€‚
* AVX-NE-CONVERTã«ã¯ã“ã‚Œã‚‰ã®ä»–ã€binary16ã«å¯¾ã™ã‚‹å‘½ä»¤ã‚‚ã‚ã‚‹ã€‚

ã“ã‚Œã‚‰ã«å¯¾å¿œã™ã‚‹Cã®çµ„ã¿è¾¼ã¿é–¢æ•°ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚

```c
#include <immintrin.h>

// VBCSTNEBF162PS
__m128 _mm_bcstnebf16_ps(const __bf16* a);
__m256 _mm256_bcstnebf16_ps(const __bf16* a);

// VCVTNEEBF162PS
__m128 _mm_cvtneebf16_ps(const __m128bh* a);
__m256 _mm256_cvtneebf16_ps(const __m256bh* a);

// VCVTNEOBF162PS
__m128 _mm_cvtneobf16_ps(const __m128bh* a);
__m256 _mm256_cvtneobf16_ps(const __m256bh* a);

// VCVTNEPS2BF16
__m128bh _mm_cvtneps_avx_pbh(__m128);
__m256bh _mm256_cvtneps_avx_pbh(__m256);
```

#### AMX-BF16

* TDPBF16PS: bfloat16Ã—bfloat16â†’binary32ã®ãƒ‰ãƒƒãƒˆç©ã‚’è¡Œã†ã€‚roundTiesToEvenã§ä¸¸ã‚ã‚‰ã‚Œã‚‹ã€‚å…¥å‡ºåŠ›ã®éæ­£è¦åŒ–æ•°ã¯0æ‰±ã„ã•ã‚Œã‚‹ã€‚MXCSRã¯å‚ç…§ã‚‚æ›´æ–°ã‚‚ã•ã‚Œãªã„ã€‚

ã“ã‚Œã«å¯¾å¿œã™ã‚‹Cã®çµ„ã¿è¾¼ã¿é–¢æ•°ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚

```c
#include <immintrin.h>

// TDPBF16PS
void __tile_dpbf16ps(__tile1024i* dst, __tile1024i src0, __tile1024i src1);
void _tile_dpbf16ps(constexpr int dst, constexpr int src1, constexpr int src2);
```

#### AVX10.2

AVX10.2ã§ã¯bfloat16ã«å¯¾ã™ã‚‹å››å‰‡æ¼”ç®—ç­‰ã®å‘½ä»¤ãŒè¿½åŠ ã•ã‚Œã‚‹è¦‹è¾¼ã¿ã§ã™ã€‚

[IntelÂ® Advanced Vector Extensions 10.2 (IntelÂ® AVX10.2) Architecture Specification](https://www.intel.com/content/www/us/en/content-details/856721/intel-advanced-vector-extensions-10-2-intel-avx10-2-architecture-specification.html)

* VADDBF16
* VCMPBF16
* VCOMISBF16
* VDIVBF16
* VF[,N]M[ADD,SUB][132,213,231]BF16
* VFPCLASSBF16
* VGETEXPBF16
* VGETMANTBF16
* VMAXBF16
* VMINBF16
* VMULBF16
* VRCPBF16
* VREDUCEBF16
* VRNDSCALEBF16
* VRSQRTBF16
* VSCALEFBF16
* VSQRTBF16
* VSUBBF16
* VMINMAXBF16: IEEE 759-2019æº–æ‹ ã®minimum/maximumç³»æ¼”ç®—
* VCVTBF162I[,U]BS: bfloat16â†’æ•´æ•°ã®å¤‰æ›

### Armç·¨

[Clang Language Extensions â€” Clang documentation](https://clang.llvm.org/docs/LanguageExtensions.html#half-precision-floating-point)

Clangçš„ã«ã¯ `__bf16` ãŒçµ„ã¿è¾¼ã¿ã®å‹ã¨ã—ã¦æä¾›ã•ã‚Œã¦ã„ã¦ã€`<arm_neon.h>` ã«ã‚ˆã£ã¦ `bfloat16_t` ãŒã‚¨ã‚¤ãƒªã‚¢ã‚¹ã¨ã—ã¦æä¾›ã•ã‚Œã‚‹ã‚ˆã†ã§ã™ã€‚

Armã®bfloat16å¯¾å¿œã¯FEAT_BF16ã¨FEAT_EBF16ã®2ã¤ã®æ‹¡å¼µã§æä¾›ã•ã‚Œã¾ã™ã€‚

FEAT_BF16: Armv8.2ä»¥é™ã®ã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ãªæ©Ÿèƒ½ã§ã€Armv8.6ä»¥é™ã§å¿…é ˆã§ã™ã€‚

* BFCVT: ã‚¹ã‚«ãƒ©ãƒ¼ã®binary32â†’bfloat16å¤‰æ›ã‚’è¡Œã†ã€‚
    * `FPCR.AH == 1` ã®å ´åˆã¯roundTiesToEvenã§ä¸¸ã‚ã€å…¥å‡ºåŠ›ã®éæ­£è¦åŒ–æ•°ã¯0ã¨ãªã‚‹ã€‚ãã†ã§ãªã„å ´åˆã¯FPCRã«å¾“ã†ã€‚
* BFCVTN, BFCVTN2: ãƒ™ã‚¯ãƒˆãƒ«ã®binary32â†’bfloat16å¤‰æ›ã‚’è¡Œã†ã€‚
    * `FPCR.AH == 1` ã®å ´åˆã¯roundTiesToEvenã§ä¸¸ã‚ã€å…¥å‡ºåŠ›ã®éæ­£è¦åŒ–æ•°ã¯0ã¨ãªã‚‹ã€‚ãã†ã§ãªã„å ´åˆã¯FPCRã«å¾“ã†ã€‚
* BFCVTNT (SVE): ãƒ™ã‚¯ãƒˆãƒ«ã®binary32â†’bfloat16å¤‰æ›ã‚’è¡Œã†ã€‚
* BFDOT: bfloat16ã®ãƒ‰ãƒƒãƒˆç©ã‚’è¨ˆç®—ã™ã‚‹ã€‚
    * FEAT_EBF16ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã¦ `FPCR.EBF == 1` ã®å ´åˆã¯æŒ™å‹•ãŒå°‘ã—å¤‰ã‚ã‚‹ã€‚
* BFMLALB, BFMLALT: ç©å’Œbfloat16Ã—bfloat16+binary32â†’binary32ã‚’è¨ˆç®—ã™ã‚‹ã€‚
* BFMMLA: bfloat16ã‚’è¦ç´ ã¨ã™ã‚‹2Ã—2è¡Œåˆ—ã®ä¹—ç®—ã‚’è¡Œã†ã€‚

ã“ã‚Œã‚‰ã«å¯¾å¿œã™ã‚‹Cã®çµ„ã¿è¾¼ã¿é–¢æ•°ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚

```c
// BFCVT
bfloat16_t vcvth_bf16_f32(float32_t a);

// BFCVTN
bfloat16x4_t vcvt_bf16_f32(float32x4_t a);
bfloat16x8_t vcvtq_low_bf16_f32(float32x4_t a);

// BFCVTN2
bfloat16x8_t vcvtq_high_bf16_f32(bfloat16x8_t inactive, float32x4_t a);

// BFDOT
float32x2_t vbfdot_f32(float32x2_t r, bfloat16x4_t a, bfloat16x4_t b);
float32x4_t vbfdotq_f32(float32x4_t r, bfloat16x8_t a, bfloat16x8_t b);
float32x2_t vbfdot_lane_f32(float32x2_t r, bfloat16x4_t a, bfloat16x4_t b, const int lane);
float32x4_t vbfdotq_laneq_f32(float32x4_t r, bfloat16x8_t a, bfloat16x8_t b, const int lane);
float32x2_t vbfdot_laneq_f32(float32x2_t r, bfloat16x4_t a, bfloat16x8_t b, const int lane);
float32x4_t vbfdotq_lane_f32(float32x4_t r, bfloat16x8_t a, bfloat16x4_t b, const int lane);

// BFMLALB
float32x4_t vbfmlalbq_f32(float32x4_t r, bfloat16x8_t a, bfloat16x8_t b);
float32x4_t vbfmlalbq_lane_f32(float32x4_t r, bfloat16x8_t a, bfloat16x4_t b, const int lane);
float32x4_t vbfmlalbq_laneq_f32(float32x4_t r, bfloat16x8_t a, bfloat16x8_t b, const int lane);

// BFMLALT
float32x4_t vbfmlaltq_f32(float32x4_t r, bfloat16x8_t a, bfloat16x8_t b);
float32x4_t vbfmlaltq_lane_f32(float32x4_t r, bfloat16x8_t a, bfloat16x4_t b, const int lane);
float32x4_t vbfmlaltq_laneq_f32(float32x4_t r, bfloat16x8_t a, bfloat16x8_t b, const int lane);

// BFMMLA
float32x4_t vbfmmlaq_f32(float32x4_t r, bfloat16x8_t a, bfloat16x8_t b);
```

FEAT_EBF16: Armv8.2ä»¥é™ã®ã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ãªæ©Ÿèƒ½ã§ã€æ‹¡å¼µã•ã‚ŒãŸå‹•ä½œã‚’å¯èƒ½ã«ã™ã‚‹ã€‚å…·ä½“çš„ã«ã¯ã€ä¸¸ã‚ãƒ¢ãƒ¼ãƒ‰ã‚„flush to zeroã®åˆ¶å¾¡ãŒå¯èƒ½ã«ãªã‚‹ã€‚

binary64ç­‰ã®é«˜ã„ç²¾åº¦ã®å€¤ã‚’binary32ã‚’çµŒç”±ã—ã¦ã‚‚ã£ã¨ä½ã„ç²¾åº¦ã®å€¤ã«å¤‰æ›ã™ã‚‹å ´åˆã€æ™®é€šã«ã‚„ã‚‹ã¨ã€ŒäºŒæ®µéšä¸¸ã‚ã€(double rounding) ã®å•é¡ŒãŒç™ºç”Ÿã—ã¾ã™ï¼ˆè©³ã—ãã¯ç§ã®åŒäººèªŒã€Œ[æµ®å‹•å°æ•°ç‚¹æ•°å°è©±](https://lab.miz-ar.info/floating-point/)ã€ã‚’å‚ç…§ã—ã¦ãã ã•ã„ï¼‰ã€‚ã“ã®å•é¡Œã¯ã€å¥‡æ•°ä¸¸ã‚ (round to odd) ã¨ã„ã†ä¸¸ã‚æ–¹æ³•ã‚’ä½¿ã†ã“ã¨ã§è§£æ¶ˆã§ãã¾ã™ã€‚Armã«ã¯ã€round to oddã§binary64â†’binary32ã®å¤‰æ›ã‚’è¡Œã†å‘½ä»¤ãŒã„ãã¤ã‹ç”¨æ„ã•ã‚Œã¦ã„ã¾ã™ï¼š

* FCVTXN, FCVTXN2, FCVTX (SVE2), FCVTXNT (SVE2)

ã“ã‚Œã‚‰ã«å¯¾å¿œã™ã‚‹Cã®çµ„ã¿è¾¼ã¿é–¢æ•°ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚

```c
// FCVTXN
float32x2_t vcvtx_f32_f64(float64x2_t a);
float32_t vcvtxd_f32_f64(float64_t a);

// FCVTXN2
float32x4_t vcvtx_high_f32_f64(float32x2_t r, float64x2_t a);
```

### RISC-Vç·¨

RISC-Vã«ã‚‚bfloat16ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹æ‹¡å¼µãŒã„ãã¤ã‹è¦å®šã•ã‚Œã¦ã„ã¾ã™ã€‚

RISC-Vã®bfloat16ã®å¯¾å¿œã§ã¯ã€éæ­£è¦åŒ–æ•°ãŒå®Œå…¨ã«ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¾ã™ã€‚

#### Zfbfmin

Zfbfminæ‹¡å¼µã¯bfloat16ã«å¯¾ã™ã‚‹æœ€ä½é™ã®ã‚µãƒãƒ¼ãƒˆã€ã¤ã¾ã‚Šbinary32ã¨ã®å¤‰æ›ã¨ã€ãƒ­ãƒ¼ãƒ‰ãƒ»ã‚¹ãƒˆã‚¢ã‚’æä¾›ã—ã¾ã™ã€‚

* FCVT.BF16.S: Convert FP32 to BF16
* FCVT.S.BF16: Convert BF16 to FP32
* FLH
* FSH
* FMV.H.X
* FMV.X.H

ãƒ­ãƒ¼ãƒ‰ãƒ»ã‚¹ãƒˆã‚¢ã®å‘½ä»¤ã¯binary16ã«å¯¾ã™ã‚‹ã‚‚ã®ï¼ˆZfhminæ‹¡å¼µã§æä¾›ã•ã‚Œã‚‹ã‚‚ã®ï¼‰ã¨å…±é€šã§ã™ã€‚

#### Zvfbfmin

Zvfbfminæ‹¡å¼µã¯ã€bfloat16ã®ãƒ™ã‚¯ãƒˆãƒ«ã«å¯¾ã™ã‚‹æœ€ä½é™ã®ã‚µãƒãƒ¼ãƒˆã€ã¤ã¾ã‚Šbinary32ã¨ã®å¤‰æ›ã‚’æä¾›ã—ã¾ã™ã€‚

* VFNCVTBF16.F.F.W: Vector convert FP32 to BF16
* VFWCVTBF16.F.F.V: Vector convert BF16 to FP32

#### Zvfbfwma

Zvfbfwmaæ‹¡å¼µã¯ã€bfloat16åŒå£«ã‚’æ›ã‘ã¦binary32ã«åŠ ãˆã‚‹ã€ã¤ã¾ã‚Šbfloat16Ã—bfloat16+binary32â†’binary32ã‚’è¡Œã†å‘½ä»¤ã‚’è¿½åŠ ã—ã¾ã™ã€‚

* VFWMACCBF16: Vector BF16 widening multiply-accumulate

## AVX-512 BF16ã‚’è©¦ã™

ç§ã®æ‰‹å…ƒã«ã‚ã‚‹AMDã®Zen4ã¯AVX-512 BF16ã‚’å®Ÿè£…ã—ã¦ã„ã¾ã™ã€‚è©¦ã—ã¦ã¿ã¾ã—ãŸã€‚

```c
#include <stdio.h>
#include <immintrin.h>

int main(void)
{
    // _mm256_set_psã®å¼•æ•°ã¯ä¸Šä½ãƒ“ãƒƒãƒˆãŒå…ˆã«æ¥ã‚‹ã“ã¨ã«æ³¨æ„
    __m128bh a = _mm256_cvtneps_pbh(_mm256_set_ps(1.0, 2.0, -1.0, 0.5, 3.5, 0.0, -2.0, 4.0));
    __m128bh b = _mm256_cvtneps_pbh(_mm256_set_ps(3.0, 5.0, -7.0, 5.0, 2.0, 5.0, 3.0, -1.5));
    __m128 acc = _mm_setzero_ps();
    __m128 result = _mm_dpbf16_ps(acc, a, b);
    _Alignas(16) float resultA[4];
    _mm_store_ps(resultA, result);
    printf("%g, %g, %g, %g\n", resultA[0], resultA[1], resultA[2], resultA[3]);
}
```

å®Ÿè¡Œçµæœï¼š

```
$ gcc -Wall -mavx512bf16 -mavx512vl avx512bf16.c
$ ./a.out
-12, 7, 9.5, 13
```

VDPBF16PSã¯ã€ç–‘ä¼¼ã‚³ãƒ¼ãƒ‰ã§æ›¸ã‘ã°

```
src1, src2: bfloat16[8]
acc: float[4]
for i in 0 ..< 4:
    acc[i] += src1[2 * i + 1] * src2[2 * i + 1]
    acc[i] += src1[2 * i + 0] * src2[2 * i + 0]
```

ã¨ã„ã†å‹•ä½œã‚’ã™ã‚‹ã®ã§ã€ä¸Šè¨˜ã‚³ãƒ¼ãƒ‰ã¯

```
acc[0] += (-2.0) * 3.0
acc[0] += 4.0 * (-1.5)
acc[1] += 3.5 * 2.0
acc[1] += 0.0 * 5.0
acc[2] += (-1.0) * (-7.0)
acc[2] += 0.5 * 5.0
acc[3] += 1.0 * 3.0
acc[3] += 2.0 * 5.0
```

ã¨ã„ã†å†…ç©ã‚’è¨ˆç®—ã—ã¾ã™ã€‚è‰¯ã•ãã†ã§ã™ã­ã€‚

## Armã®FEAT_BF16ã‚’è©¦ã™

Appleã®Mã‚·ãƒªãƒ¼ã‚ºã§ã¯ã€M2ä»¥é™ã§FEAT_BF16ã«å¯¾å¿œã—ã¦ã„ã‚‹ã‚ˆã†ã§ã™ï¼ˆå‚è€ƒï¼š[Apple Silicon M2ã¯M1ã‚·ãƒªãƒ¼ã‚ºã¨æ¯”ã¹ã¦å‘½ä»¤ã‚»ãƒƒãƒˆãŒæ‹¡å¼µã•ã‚Œã¦ã„ã‚‹](https://qiita.com/zacky1972/items/5deec6b139a76246aeee)ï¼‰ã€‚ä¸€æ–¹ã€Apple M4ã®æ™‚ç‚¹ã§ã‚‚FEAT_EBF16ã«ã¯å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚

```
$ # Apple M4ã§ã®å®Ÿè¡Œçµæœ
$ sysctl hw | grep BF16
hw.optional.arm.FEAT_BF16: 1
hw.optional.arm.FEAT_EBF16: 0
```

FEAT_BF16ã‚’è©¦ã™ã‚³ãƒ¼ãƒ‰ã¯ã€Œ[æµ®å‹•å°æ•°ç‚¹æ•°ã‚ªã‚¿ã‚¯ãŒM1 Macã‚’è§¦ã£ã¦ã¿ãŸ](https://qiita.com/mod_poppo/items/fb18f2a1441e74af29a3#bfloat16-%E9%9D%9E%E5%AF%BE%E5%BF%9C)ã€ã«ã‚‚æ›¸ãã¾ã—ãŸã€‚ã“ã“ã§ã¯åŒã˜ã‚³ãƒ¼ãƒ‰ã‚’Apple M4ã§å®Ÿè¡Œã—ã¦ã¿ã¾ã™ã€‚

```c
#include <stdio.h>
#include <arm_acle.h>
#include <arm_neon.h>

int main(void)
{
#if defined(__ARM_FEATURE_BF16)
    puts("__ARM_FEATURE_BF16 is defined");
#else
    puts("__ARM_FEATURE_BF16 is not defined");
#endif
#if defined(__ARM_BF16_FORMAT_ALTERNATIVE)
    puts("__ARM_BF16_FORMAT_ALTERNATIVE is defined");
#else
    puts("__ARM_BF16_FORMAT_ALTERNATIVE is not defined");
#endif
#if defined(__ARM_BF16_FORMAT_ALTERNATIVE)
    float32_t x = 3.14f;
    bfloat16_t y = vcvth_bf16_f32(x);
    float32_t z = vcvtah_f32_bf16(y);
    printf("%a -> %a\n", x, z);
#endif
}
```

```
$ clang -march=armv8.6-a bf16.c
$ ./a.out
__ARM_FEATURE_BF16 is defined
__ARM_BF16_FORMAT_ALTERNATIVE is defined
0x1.91eb86p+1 -> 0x1.92p+1
```

å¥‡æ•°ä¸¸ã‚ã®ä¾‹ã‚‚è¼‰ã›ã¦ãŠãã¾ã™ã€‚

```c
#include <stdio.h>
#include <arm_acle.h>
#include <arm_neon.h>

int main(void)
{
    float a = vcvtxd_f32_f64(0x1.70000001p10);
    float b = vcvtxd_f32_f64(0x1.70000001p300);
    printf("%a, %a\n", a, b);
}
```

```
$ clang cvtx.c
$ ./a.out
0x1.700002p+10, 0x1.fffffep+127
```

Armã®å¥‡æ•°ä¸¸ã‚å‘½ä»¤ã¯ã€çµ¶å¯¾å€¤ãŒå¤§ããã¦binary32ã§è¡¨ç¾ã§ããªã„æœ‰é™å€¤ã‚’ã€ã€Œbinary32ã®ç„¡é™å¤§ã€ã§ã¯ãªãã€Œbinary32ã®æœ‰é™ã®æœ€å¤§å€¤ã€ã«å¤‰æ›ã™ã‚‹ã‚ˆã†ã§ã™ã€‚ãƒã‚¸ã§ï¼Ÿã£ã¦æ„Ÿã˜ã§ã™ãŒã€ã“ã®å¾Œbfloat16ã«å¤‰æ›ã™ã‚‹æ™‚ã«ç„¡é™å¤§ã«ãªã‚‹ã‹ã‚‰æ°—ã«ã—ãªã„ã€ã£ã¦ã“ã¨ã§ã™ã‹ã­ã€‚
